{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined and Write Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data directory\n",
    "CWD = os.getcwd()\n",
    "cms_data_dir = os.path.join(CWD, 'CMSData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some years columns are capitalized and other years the columns are lowercase:\n",
    "capitalization_dict = {\n",
    "    '2012': str.upper,\n",
    "    '2013': str.upper,\n",
    "    '2014': str.lower,\n",
    "    '2015': str.lower,\n",
    "    '2016': str.upper,\n",
    "    '2017': str.lower,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CMS Part B dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dtypes based on https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/...\n",
    "#Medicare-Provider-Charge-Data/Physician-and-Other-Supplier2017\n",
    "partB_dtypes = {\n",
    "    'npi': 'int64',\n",
    "    'nppes_provider_last_org_name': 'str',\n",
    "    'nppes_provider_first_name': 'str',\n",
    "    'nppes_provider_mi': 'str',\n",
    "    'nppes_credentials': 'str',\n",
    "    'nppes_provider_gender': 'str',\n",
    "    'nppes_entity_code': 'str',\n",
    "    'nppes_provider_street1': 'str',\n",
    "    'nppes_provider_street2': 'str',\n",
    "    'nppes_provider_city': 'str',\n",
    "    'nppes_provider_zip': 'str',\n",
    "    'nppes_provider_state': 'str',\n",
    "    'nppes_provider_country': 'str',\n",
    "    'provider_type': 'str',\n",
    "    'medicare_participation_indicator': 'str',\n",
    "    'place_of_service': 'str',\n",
    "    'hcpcs_code': 'str',\n",
    "    'hcpcs_description': 'str',\n",
    "    'hcpcs_drug_indicator': 'str',\n",
    "    'line_srvc_cnt': 'float64',\n",
    "    'bene_unique_cnt': 'float64',    \n",
    "    'bene_day_srvc_cnt': 'float64',\n",
    "    'average_medicare_allowed_amt': 'float64',\n",
    "    'average_submitted_chrg_amt': 'float64',\n",
    "    'average_medicare_payment_amt': 'float64',\n",
    "    'average_medicare_standard_amt': 'float64',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dfs for all years - TAKE A FEW MINUTES\n",
    "years = ['2012','2013','2014','2015','2016','2017']\n",
    "dfs   = []\n",
    "\n",
    "for year in years:\n",
    "    file = os.path.join(cms_data_dir, f'cms{year}.txt')\n",
    "    dtypes = dict(zip(list(map(capitalization_dict[year], partB_dtypes.keys())), list(partB_dtypes.values()))) #get correct column capitalization and dtype\n",
    "    df = pd.read_csv(file, delimiter='\\t', dtype=dtypes)\n",
    "    df.columns = map(str.lower, df.columns)  # make all variable names lowercase\n",
    "    df['year'] = year #add Year column \n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "partB_df = pd.concat(dfs, axis=0, ignore_index=True, sort=False)\n",
    "partB_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing NPI and HCPCS - \"Medicare fraud detection using neural networks\" (Johnson, Khoshgoftaar 2019)\n",
    "partB_df = partB_df.dropna(subset = ['npi','hcpcs_code'])\n",
    "partB_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows corresponding to drugs because LINE_SRVC_CNT for them is not a desirable count\n",
    "partB_df = partB_df[(partB_df['hcpcs_drug_indicator'] == 'N')]\n",
    "partB_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep variables based on \"Medicare fraud detection using neural networks\" (Johnson, Khoshgoftaar 2019)\n",
    "partB_variables_to_keep = [\n",
    "    'npi',\n",
    "    'provider_type',\n",
    "    'nppes_provider_city', # keep\n",
    "    'nppes_provider_zip', # keep\n",
    "    'nppes_provider_state', # keep\n",
    "    'nppes_provider_country', # keep\n",
    "    'hcpcs_code',  # not in paper but kept\n",
    "    'hcpcs_description',  # not in paper but kept\n",
    "    'hcpcs_drug_indicator',  # not in paper but kept\n",
    "    'place_of_service',  # not in paper but kept\n",
    "    'nppes_provider_gender',\n",
    "    'line_srvc_cnt',\n",
    "    'bene_unique_cnt',\n",
    "    'bene_day_srvc_cnt',\n",
    "    'average_submitted_chrg_amt',\n",
    "    'average_medicare_payment_amt',\n",
    "    'year' # need Year for labeling\n",
    "]\n",
    "partB_df = partB_df[partB_variables_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partB_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partB_df.loc[partB_df['npi'] == 1003000142][['npi',\n",
    "                                             'provider_type',\n",
    "                                             'place_of_service',\n",
    "                                             'line_srvc_cnt',\n",
    "                                             'average_submitted_chrg_amt']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partB_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all combined CMS to csv\n",
    "#partB_df.to_csv('combined-partB-data-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LEIE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leie_data_dir = os.path.join(CWD, 'LEIEData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leie_dtypes = {\n",
    "    'LASTNAME': 'str',\n",
    "    'FIRSTNAME': 'str',\n",
    "    'MIDNAME': 'str',\n",
    "    'BUSNAME' : 'str',\n",
    "    'GENERAL': 'str',\n",
    "    'SPECIALTY': 'str',\n",
    "    'UPIN': 'str',\n",
    "    'NPI': 'int64',\n",
    "    'DOB': 'str',\n",
    "    'ADDRESS': 'str',\n",
    "    'CITY': 'str',\n",
    "    'STATE': 'str',\n",
    "    'ZIP': 'str',\n",
    "    'EXCLTYPE': 'str',\n",
    "    'EXCLDATE': 'int64',\n",
    "    'REINDATE': 'int64',\n",
    "    'WAIVERDATE': 'int64',\n",
    "    'WVRSTATE': 'str',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEIE data is monthly between 01/2018 (1801) - 12/2019 (1912)\n",
    "year_months = ['1801','1802','1803','1804','1805','1806','1807','1808','1809','1810','1811','1812',\n",
    "            '1901','1902','1903','1904','1905','1906','1907','1908','1909','1910','1911','1912']\n",
    "dfs = []\n",
    "\n",
    "for year_month in year_months:\n",
    "    file = os.path.join(leie_data_dir, f'leie{year_month}-excl.csv')\n",
    "    df   = pd.read_csv(file, dtype=leie_dtypes)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "leie_df = pd.concat(dfs, axis=0, ignore_index=True, sort=False)\n",
    "leie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NPI = 0, which means missing - A LOT ARE MISSING, which is a problem for the data\n",
    "leie_df = leie_df[leie_df['npi'] != 0]\n",
    "leie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep exclusions most related to Fraud\n",
    "exclusions_to_keep = [\n",
    "    '1128a1',\n",
    "    '1128a2',\n",
    "    '1128a3',\n",
    "    '1128b4',\n",
    "    '1128b7',\n",
    "    '1128c3Gi',\n",
    "    '1128c3gii',\n",
    "]\n",
    "leie_df = leie_df[leie_df['excltype'].isin(exclusions_to_keep)]\n",
    "leie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leie_df['excltype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all combined LEIE to csv\n",
    "#partB_df.to_csv('combined-leie-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "leie_df['excldate'] = pd.to_datetime(leie_df['excldate'], format='%Y%m%d', errors ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round excl date to the nearest year Johnson & Khoshgoftaar (2019)\n",
    "def round_to_year(dt=None):\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    if month >= 6:\n",
    "        year = year + 1\n",
    "    return datetime(year=year,month=1,day=1)\n",
    "\n",
    "leie_df['excl_year'] = leie_df.excldate.apply(lambda x: round_to_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make exclusion dict \n",
    "# 1215053665 has 2 exclusions, so sort df to get latest year\n",
    "excl_year_dict = dict([npi, year] for npi, year in zip(leie_df.sort_values(by='excl_year').npi, leie_df.sort_values(by='excl_year').excl_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label as 0 or 1\n",
    "partB_df['excl_year'] = partB_df['npi'].map(excl_year_dict)\n",
    "partB_df['excl_year'] = partB_df['excl_year'].fillna(datetime(year=1900,month=1,day=1)) # fill NaN, physicians without exclusion, with year 1900\n",
    "\n",
    "partB_df['year'] = pd.to_datetime(partB_df['year'].astype(str), format='%Y', errors ='ignore')\n",
    "partB_df['fraudulent'] = np.where(partB_df['year'] < partB_df['excl_year'], 1, 0) # compare year vs. exclusion year to get Fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(partB_df.fraudulent.value_counts())\n",
    "print('Fraudulent physicians are: {0}% of all data'.format(str(np.round((8867/35359427)*100,decimals = 6)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit partB_df.to_csv('labeled-data-v1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
